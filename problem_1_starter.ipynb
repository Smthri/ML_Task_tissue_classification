{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem_1_starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eeb7532df2be4cf2ba25691eabeb48d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb00df8ffc1a4eae933e70287ed9bf48",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_582a0b0515dc4e8096abffaf51506f6a",
              "IPY_MODEL_fd5e7d44dd5d4782a6f9f5ee066ec923"
            ]
          }
        },
        "fb00df8ffc1a4eae933e70287ed9bf48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "582a0b0515dc4e8096abffaf51506f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81b4998273d5484ea8362089c2f0ae70",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 45,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 45,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_627297e51f824f90911882ff54500c89"
          }
        },
        "fd5e7d44dd5d4782a6f9f5ee066ec923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3167c62a5cac4fcab95e81d1fe5a8a6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45/45 [03:28&lt;00:00,  4.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ae0b54c54294174b8428a2fd1f25a90"
          }
        },
        "81b4998273d5484ea8362089c2f0ae70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "627297e51f824f90911882ff54500c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3167c62a5cac4fcab95e81d1fe5a8a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ae0b54c54294174b8428a2fd1f25a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89ce09305dd41a18deb794ce9e7abbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba564b750d86485e82901e28137d4fa0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ebaf8c08b4104513809b5dfefd3f6517",
              "IPY_MODEL_7ef64ea579804abf9976e0a2100e14a3"
            ]
          }
        },
        "ba564b750d86485e82901e28137d4fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebaf8c08b4104513809b5dfefd3f6517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83ccdf2320154bf2a51aba0ea5be1940",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 45,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 45,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30788e32776a478e9690bc34e6b12280"
          }
        },
        "7ef64ea579804abf9976e0a2100e14a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4cc07e25ecac4f9fbfa825d35e1b5bb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45/45 [03:14&lt;00:00,  4.32s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_769399236a864646b3b8b9b278622eae"
          }
        },
        "83ccdf2320154bf2a51aba0ea5be1940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30788e32776a478e9690bc34e6b12280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cc07e25ecac4f9fbfa825d35e1b5bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "769399236a864646b3b8b9b278622eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffa971f148bc42ecb4e173f94b8a1739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_023b5d9fd72846af839cf2bcc5c9847d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4edc65a77c5741728dcbb9c9589fb03a",
              "IPY_MODEL_436d9940170d42fcb3ff16db58e1e9f4"
            ]
          }
        },
        "023b5d9fd72846af839cf2bcc5c9847d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4edc65a77c5741728dcbb9c9589fb03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6c23b5176ac41a48d3131eb5c536e08",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 45,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 45,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f048431f8081478094558c41b101ed7f"
          }
        },
        "436d9940170d42fcb3ff16db58e1e9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_487a811daf9544bea5886f00c784c5ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45/45 [03:16&lt;00:00,  4.36s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89e4753bd37c430f87394deb0942bcd5"
          }
        },
        "d6c23b5176ac41a48d3131eb5c536e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f048431f8081478094558c41b101ed7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "487a811daf9544bea5886f00c784c5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89e4753bd37c430f87394deb0942bcd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31052ab1ca834bda8b95b72ea6c17989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b58de45e885424fb3daa6bd6d697cef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eea53d26cb534f93972921f3e2376591",
              "IPY_MODEL_22dc30bcd04347198d9e4d977bd6cb88"
            ]
          }
        },
        "5b58de45e885424fb3daa6bd6d697cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eea53d26cb534f93972921f3e2376591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2df74b8b1be849de9421bc291db7ed6c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 45,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 45,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b1aece8cda44142910d80b28771469a"
          }
        },
        "22dc30bcd04347198d9e4d977bd6cb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3f6032308a54b0584b6593d288a8b24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45/45 [04:04&lt;00:00,  5.43s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fd15a514e1144418ab6408e0fd9f7b1"
          }
        },
        "2df74b8b1be849de9421bc291db7ed6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b1aece8cda44142910d80b28771469a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3f6032308a54b0584b6593d288a8b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fd15a514e1144418ab6408e0fd9f7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atqZGIIyNSBb"
      },
      "source": [
        "#**Практическое задание №1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5g3lUhNNBy"
      },
      "source": [
        "Установка необходимых пакетов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGBk36LpukIu"
      },
      "source": [
        "!pip install -q libtiff\n",
        "!pip install -q tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vQDLyHEO1Ux"
      },
      "source": [
        "Монтирование Вашего Google Drive к текущему окружению:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G5KkA1Nu5M9",
        "outputId": "b4732f84-1341-4d95-883a-0dcb77b0fe46"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "#base_dir='./'\n",
        "base_dir ='drive/MyDrive/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6-mtI6W1y1b"
      },
      "source": [
        "В переменную PROJECT_DIR необходимо прописать путь к директории на Google Drive, в которую Вы загрузили zip архивы с предоставленными наборами данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdvM-BUTvfSV"
      },
      "source": [
        "# todo\n",
        "#PROJECT_DIR='./'\n",
        "PROJECT_DIR = 'ML_задание/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Num5lHV6912"
      },
      "source": [
        "Константы, которые пригодятся в коде далее:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab2yCwDm7Fqb"
      },
      "source": [
        "EVALUATE_ONLY = True\n",
        "TEST_ON_LARGE_DATASET = False\n",
        "TISSUE_CLASSES = ('ADI', 'BACK', 'DEB', 'LYM', 'MUC', 'MUS', 'NORM', 'STR', 'TUM')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgY-ux5qOI0k"
      },
      "source": [
        "Импорт необходимых зависимостей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLHQhqiSIyvK"
      },
      "source": [
        "from pathlib import Path\n",
        "from libtiff import TIFF\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm.notebook import tqdm\n",
        "from time import sleep\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKLI3lUyMYO9"
      },
      "source": [
        "---\n",
        "### Класс Dataset\n",
        "\n",
        "Предназначен для работы с наборами данных, хранящихся на Google Drive, обеспечивает чтение изображений и соответствующих меток, а также формирование пакетов (батчей)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N169efsw1ej"
      },
      "source": [
        "class Dataset:\n",
        "\n",
        "    def __init__(self, name, gdrive_dir):\n",
        "        self.name = name\n",
        "        self.is_loaded = False\n",
        "        p = Path(base_dir + gdrive_dir + name + '.npz') \n",
        "        if p.exists():\n",
        "            print(f'Loading dataset {self.name} from npz.')\n",
        "            np_obj = np.load(str(p))\n",
        "            self.images = np_obj['data']\n",
        "            self.labels = np_obj['labels']\n",
        "            self.n_files = self.images.shape[0]\n",
        "            self.is_loaded = True\n",
        "            print(f'Done. Dataset {name} consists of {self.n_files} images.')\n",
        "        else:\n",
        "          print(f'WARNING: path {str(p)} doesn\\'t exist')\n",
        "\n",
        "    def image(self, i):\n",
        "        # read i-th image in dataset and return it as numpy array\n",
        "        if self.is_loaded:\n",
        "            return self.images[i, :, :, :]\n",
        "\n",
        "    def images_seq(self, start=0, n=None):\n",
        "        # sequential access to images inside dataset (is needed for testing)\n",
        "        for i in range(start, start + self.n_files if not n else start + n):\n",
        "            yield self.image(i)\n",
        "\n",
        "    def random_image_with_label(self):\n",
        "        # get random image with label from dataset\n",
        "        i = np.random.randint(self.n_files)\n",
        "        return self.image(i), self.labels[i]\n",
        "  \n",
        "    def random_batch_with_labels(self, n):\n",
        "        # create random batch of images with labels (is needed for training)\n",
        "        indices = np.random.choice(self.n_files, n)\n",
        "        imgs = []\n",
        "        for i in indices:\n",
        "            img = self.image(i)\n",
        "            imgs.append(self.image(i))\n",
        "        logits = np.array([self.labels[i] for i in indices])\n",
        "        return np.stack(imgs), logits\n",
        "\n",
        "    def image_with_label(self, i: int):\n",
        "        # return i-th image with label from dataset\n",
        "        return self.image(i), self.labels[i]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-LvGqeHYgus"
      },
      "source": [
        "### Пример использвания класса Dataset\n",
        "Загрузим обучающий набор данных, получим произвольное изображение с меткой. После чего визуализируем изображение, выведем метку. В будущем, этот кусок кода можно закомментировать или убрать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HhObWEjGJ1um",
        "outputId": "c5998677-43f6-4d0b-967e-390198a68065"
      },
      "source": [
        "'''d_train_tiny = Dataset('train_tiny', PROJECT_DIR)\n",
        "\n",
        "img, lbl = d_train_tiny.random_image_with_label()\n",
        "print()\n",
        "print(f'Got numpy array of shape {img.shape}, and label with code {lbl}.')\n",
        "print(f'Label code corresponds to {TISSUE_CLASSES[lbl]} class.')\n",
        "\n",
        "pil_img = Image.fromarray(img)\n",
        "IPython.display.display(pil_img)'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"d_train_tiny = Dataset('train_tiny', PROJECT_DIR)\\n\\nimg, lbl = d_train_tiny.random_image_with_label()\\nprint()\\nprint(f'Got numpy array of shape {img.shape}, and label with code {lbl}.')\\nprint(f'Label code corresponds to {TISSUE_CLASSES[lbl]} class.')\\n\\npil_img = Image.fromarray(img)\\nIPython.display.display(pil_img)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaBXXCWeVLYb"
      },
      "source": [
        "---\n",
        "### Класс Metrics\n",
        "\n",
        "Реализует метрики точности, используемые для оценивания модели:\n",
        "1. точность,\n",
        "2. сбалансированную точность."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unQ7azTinCZ"
      },
      "source": [
        "class Metrics:\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(gt: List[int], pred: List[int]):\n",
        "        assert len(gt) == len(pred), 'gt and prediction should be of equal length'\n",
        "        print([f'{i[0]} : {i[1]}' for i in list(zip(gt, pred))[:5]])\n",
        "        return sum(int(i[0] == i[1]) for i in zip(gt, pred)) / len(gt)\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy_balanced(gt: List[int], pred: List[int]):\n",
        "        return balanced_accuracy_score(gt, pred)\n",
        "\n",
        "    @staticmethod\n",
        "    def print_all(gt: List[int], pred: List[int], info: str):\n",
        "        print(f'metrics for {info}:')\n",
        "        print('\\t accuracy {:.4f}:'.format(Metrics.accuracy(gt, pred)))\n",
        "        print('\\t balanced accuracy {:.4f}:'.format(Metrics.accuracy_balanced(gt, pred)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AHzTJVGU5k"
      },
      "source": [
        "---\n",
        "### Класс Model\n",
        "\n",
        "Класс, хранящий в себе всю информацию о модели.\n",
        "\n",
        "Вам необходимо реализовать методы save, load для сохранения и заргрузки модели. Особенно актуально это будет во время тестирования на дополнительных наборах данных.\n",
        "\n",
        "> *Пожалуйста, убедитесь, что сохранение и загрузка модели работает корректно. Для этого обучите модель, протестируйте, сохраните ее в файл, перезапустите среду выполнения, загрузите обученную модель из файла, вновь протестируйте ее на тестовой выборке и убедитесь в том, что получаемые метрики совпадают с полученными для тестовой выбрки ранее.*\n",
        "\n",
        "\n",
        "Также, Вы можете реализовать дополнительные функции, такие как:\n",
        "1. валидацию модели на части обучающей выборки;\n",
        "2. использование кроссвалидации;\n",
        "3. автоматическое сохранение модели при обучении;\n",
        "4. загрузку модели с какой-то конкретной итерации обучения (если используется итеративное обучение);\n",
        "5. вывод различных показателей в процессе обучения (например, значение функции потерь на каждой эпохе);\n",
        "6. построение графиков, визуализирующих процесс обучения (например, график зависимости функции потерь от номера эпохи обучения);\n",
        "7. автоматическое тестирование на тестовом наборе/наборах данных после каждой эпохи обучения (при использовании итеративного обучения);\n",
        "8. автоматический выбор гиперпараметров модели во время обучения;\n",
        "9. сохранение и визуализацию результатов тестирования;\n",
        "10. Использование аугментации и других способов синтетического расширения набора данных (дополнительным плюсом будет обоснование необходимости и обоснование выбора конкретных типов аугментации)\n",
        "11. и т.д.\n",
        "\n",
        "Полный список опций и дополнений приведен в презентации с описанием задания.\n",
        "\n",
        "При реализации дополнительных функций допускается добавление параметров в существующие методы и добавление новых методов в класс модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pkMiB6mJ7JQ",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba037057-a958-4b88-8720-ddd9e33d952b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import cv2\n",
        "import os\n",
        "from random import random, randint\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "%load_ext tensorboard\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Using architecture from https://openaccess.thecvf.com/content_cvpr_2016/papers/Hou_Patch-Based_Convolutional_Neural_CVPR_2016_paper.pdf\n",
        "        \n",
        "        self.input_shape=(224, 224, 3)\n",
        "\n",
        "        self.preproc_batch = self.preproc_batch_default\n",
        "        self.model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, input_shape=self.input_shape, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.ReLU(),\n",
        "          tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=3),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=128, kernel_size=5, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.ReLU(),\n",
        "          tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=256, kernel_size=3, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.ReLU(),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=256, kernel_size=3, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.ReLU(),\n",
        "          tf.keras.layers.MaxPool2D(pool_size=3, strides=1),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=512, kernel_size=3, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.ReLU(),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=512, kernel_size=3, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.ReLU(),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=1024, kernel_size=3, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.BatchNormalization(),\n",
        "          tf.keras.layers.ReLU(),\n",
        "\n",
        "          tf.keras.layers.Conv2D(filters=1024, kernel_size=3, kernel_regularizer=l2(.0003)),\n",
        "          tf.keras.layers.ReLU(),\n",
        "\n",
        "          tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "          tf.keras.layers.Dense(units=1024, activation='relu'),\n",
        "          tf.keras.layers.Dropout(rate=0.5),\n",
        "\n",
        "          tf.keras.layers.Dense(units=1024, activation='relu'),\n",
        "          tf.keras.layers.Dropout(rate=0.5),\n",
        "\n",
        "          tf.keras.layers.Dense(units=9, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        self.save_path=base_dir + PROJECT_DIR + 'best.h5'\n",
        "        self.checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=self.save_path,\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        self.model.compile(optimizer='adam',\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                           metrics=['accuracy'])\n",
        "        \n",
        "        self.logdir = base_dir + PROJECT_DIR + 'logs'\n",
        "        self.tensorboard_callback = tf.keras.callbacks.TensorBoard(self.logdir, histogram_freq=1)\n",
        "\n",
        "    def summary(self):\n",
        "      print(self.model.summary())\n",
        "\n",
        "    def save(self, name: str):\n",
        "        # Unnecessary, the callback saves the best model instance during training\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def load(name: str):\n",
        "        model = Model()\n",
        "        if os.path.exists(base_dir + PROJECT_DIR + f'{name}.h5'):\n",
        "          model.model = tf.keras.models.load_model(base_dir + PROJECT_DIR + f'{name}.h5')\n",
        "\n",
        "        if 'best_densenet' in name:\n",
        "          print('Changing preprocessor')\n",
        "          model.preproc_batch = model.preproc_batch_densenset\n",
        "        elif 'best_resnet' in name:\n",
        "          print('Changing preprocessor')\n",
        "          model.preproc_batch = model.preproc_batch_resnet\n",
        "        else:\n",
        "          model.preproc_batch = model.preproc_batch_default\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, train_ds):\n",
        "        print(f'training started')\n",
        "        \n",
        "        for i in range(70):\n",
        "\n",
        "          n = 500\n",
        "          x_train, y_train = train_ds.random_batch_with_labels(n)\n",
        "          x_train = self.preproc_batch(x_train)\n",
        "\n",
        "          x_val, y_val = train_ds.random_batch_with_labels(150)\n",
        "          x_val = self.preproc_batch(x_val, 0)\n",
        "\n",
        "          print(x_train.shape, y_train.shape)\n",
        "          self.model.fit(x_train, y_train, epochs=40, callbacks=[self.checkpoint_callback], validation_data=(x_val, y_val))\n",
        "\n",
        "        print(f'training done')\n",
        "        pass\n",
        "\n",
        "    def preproc_batch_default(self, batch, thr=.5):\n",
        "      imgs = []\n",
        "      for image in batch:\n",
        "        if random() < thr:\n",
        "          border = randint(10, 40)\n",
        "          image = image[border:-border, border:-border]\n",
        "        img = cv2.resize(image/255., self.input_shape[:2], interpolation=cv2.INTER_CUBIC)\n",
        "        if random() < thr:\n",
        "          img = img[:, ::-1]\n",
        "        if random() < thr:\n",
        "          img = img[::-1]\n",
        "        img -= np.mean(img)\n",
        "        img /= (np.std(img) + 0.00001)\n",
        "        imgs.append(img)\n",
        "\n",
        "      return np.stack(imgs)\n",
        "\n",
        "    def preproc_batch_densenset(self, batch, thr=None):\n",
        "      imgs = []\n",
        "      for image in batch:\n",
        "        imgs.append(tf.keras.applications.densenet.preprocess_input(image.astype(np.float)))\n",
        "\n",
        "      return np.stack(imgs)\n",
        "\n",
        "    def preproc_batch_resnet(self, batch, thr=None):\n",
        "      imgs = []\n",
        "      for image in batch:\n",
        "        imgs.append(tf.keras.applications.resnet_v2.preprocess_input(image.astype(np.float)))\n",
        "\n",
        "      return np.stack(imgs)\n",
        "\n",
        "    def preproc_batch_deprecated(self, batch, thr=.5):\n",
        "      imgs = []\n",
        "      for image in batch:\n",
        "        if random() < thr:\n",
        "          border = randint(10, 40)\n",
        "          image = image[border:-border, border:-border]\n",
        "        img = cv2.resize(image/255., self.input_shape[:2], interpolation=cv2.INTER_CUBIC)\n",
        "        if random() < thr:\n",
        "          img = img[:, ::-1]\n",
        "        if random() < thr:\n",
        "          img = img[::-1]\n",
        "        imgs.append(img)\n",
        "\n",
        "      return np.stack(imgs)\n",
        "\n",
        "    def test_on_dataset(self, dataset: Dataset, limit=None):\n",
        "        # you can upgrade this code if you want to speed up testing using batches\n",
        "        predictions = []\n",
        "        n = dataset.n_files if not limit else int(dataset.n_files * limit)\n",
        "        batch_size = 100\n",
        "        current = 0\n",
        "        for current in tqdm(range(0, n, min(batch_size, n - current))):\n",
        "          for img in self.preproc_batch(dataset.images_seq(current, min(batch_size, n - current)), 0):\n",
        "            predictions.append(self.test_on_image(img[np.newaxis, :]))\n",
        "        return predictions\n",
        "\n",
        "    def test_on_image(self, img: np.ndarray):\n",
        "      prediction = self.model.predict(img)\n",
        "      return np.argmax(prediction)\n",
        "\n",
        "    @staticmethod\n",
        "    def stacked_test(test_ds, models):\n",
        "\n",
        "      preds_clean = np.zeros((len(models), test_ds.n_files), dtype=np.int8)\n",
        "      for i, name in enumerate(models):\n",
        "        model = Model.load(name)\n",
        "        preds_clean[i] = model.test_on_dataset(test_ds, limit=1.)\n",
        "        print(f'Model {name} evaluated')\n",
        "\n",
        "      preds = preds_clean.T\n",
        "\n",
        "      preds_stacked = np.zeros(len(preds), dtype=np.int8)\n",
        "      for i, p in enumerate(preds):\n",
        "        preds_stacked[i] = np.argmax(np.bincount(p))\n",
        "\n",
        "      return preds_stacked\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpTB6lMr00A"
      },
      "source": [
        "---\n",
        "### Классификация изображений\n",
        "\n",
        "Используя введенные выше классы можем перейти уже непосредственно к обучению модели классификации изображений. Пример общего пайплайна решения задачи приведен ниже. Вы можете его расширять и улучшать. В данном примере используются наборы данных 'train_small' и 'test_small'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cTOuZD01Up6",
        "outputId": "a42ef7ab-8896-419f-922c-37f1d2c26a3a"
      },
      "source": [
        "#d_train = Dataset('train', PROJECT_DIR)\n",
        "d_test = Dataset('test', PROJECT_DIR)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset test from npz.\n",
            "Done. Dataset test consists of 4500 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBi0XpXg8_wq",
        "scrolled": true,
        "outputId": "41e02230-8208-42ab-c136-301bcb9550b5"
      },
      "source": [
        "model = Model.load('models/best6')\n",
        "model.summary()\n",
        "if not EVALUATE_ONLY:\n",
        "  model.train(d_train)\n",
        "\n",
        "  model.load('best')\n",
        "\n",
        "#%tensorboard --logdir logs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 220, 220, 64)      4864      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 220, 220, 64)      256       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 220, 220, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 73, 73, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 69, 69, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 69, 69, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 69, 69, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 34, 34, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 30, 30, 256)       590080    \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 30, 30, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 26, 26, 512)       2048      \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 26, 26, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 24, 24, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 22, 22, 1024)      4719616   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 1024)      4096      \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 22, 22, 1024)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 20, 20, 1024)      9438208   \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 20, 20, 1024)      0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 9225      \n",
            "=================================================================\n",
            "Total params: 20,908,169\n",
            "Trainable params: 20,904,713\n",
            "Non-trainable params: 3,456\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcM2EiRMVP93"
      },
      "source": [
        "Пример тестирования модели на части набора данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AqmeLEKqrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "eeb7532df2be4cf2ba25691eabeb48d4",
            "fb00df8ffc1a4eae933e70287ed9bf48",
            "582a0b0515dc4e8096abffaf51506f6a",
            "fd5e7d44dd5d4782a6f9f5ee066ec923",
            "81b4998273d5484ea8362089c2f0ae70",
            "627297e51f824f90911882ff54500c89",
            "3167c62a5cac4fcab95e81d1fe5a8a6d",
            "9ae0b54c54294174b8428a2fd1f25a90"
          ]
        },
        "outputId": "6e16d3c2-16ae-467e-8f0a-3d3db85e3a21"
      },
      "source": [
        "# evaluating model on x% of test dataset\n",
        "limit=1.\n",
        "pred_1 = model.test_on_dataset(d_test, limit=limit)\n",
        "Metrics.print_all(d_test.labels[:len(pred_1)], pred_1, f'{limit*100}% of test')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eeb7532df2be4cf2ba25691eabeb48d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "metrics for 100.0% of test:\n",
            "['0 : 0', '0 : 0', '0 : 0', '0 : 0', '0 : 0']\n",
            "\t accuracy 0.8836:\n",
            "\t balanced accuracy 0.8836:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSwvHVVzVWZ5"
      },
      "source": [
        "Пример тестирования модели на полном наборе данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjI_sbMi3TMY"
      },
      "source": [
        "# evaluating model on full test dataset (may take time)\n",
        "if TEST_ON_LARGE_DATASET:\n",
        "    pred_2 = Model.stacked_test(d_test, ['models/best6', 'models/best_resnet', 'models/best_densenet'])\n",
        "    Metrics.print_all(d_test.labels, pred_2, 'test')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvyEHdxEB18o"
      },
      "source": [
        "Результат работы пайплайна обучения и тестирования выше тоже будет оцениваться. Поэтому не забудьте присылать на проверку ноутбук с выполнеными ячейками кода с демонстрациями метрик обучения, графиками и т.п. В этом пайплайне Вам необходимо продемонстрировать работу всех реализованных дополнений, улучшений и т.п.\n",
        "\n",
        "<font color=\"red\">\n",
        "Настоятельно рекомендуется после получения пайплайна с полными результатами обучения экспортировать ноутбук в pdf (файл -> печать) и прислать этот pdf вместе с самим ноутбуком.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSKAvVI6uCW"
      },
      "source": [
        "### Тестирование модели на других наборах данных\n",
        "\n",
        "Ваша модель должна поддерживать тестирование на других наборах данных. Для удобства, Вам предоставляется набор данных test_tiny, который представляет собой малую часть (2% изображений) набора test. Ниже приведен фрагмент кода, который будет осуществлять тестирование для оценивания Вашей модели на дополнительных тестовых наборах данных.\n",
        "\n",
        "<font color=\"red\">\n",
        "Прежде чем отсылать задание на проверку, убедитесь в работоспособности фрагмента кода ниже.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdY3uTt87tqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "b89ce09305dd41a18deb794ce9e7abbd",
            "ba564b750d86485e82901e28137d4fa0",
            "ebaf8c08b4104513809b5dfefd3f6517",
            "7ef64ea579804abf9976e0a2100e14a3",
            "83ccdf2320154bf2a51aba0ea5be1940",
            "30788e32776a478e9690bc34e6b12280",
            "4cc07e25ecac4f9fbfa825d35e1b5bb0",
            "769399236a864646b3b8b9b278622eae",
            "ffa971f148bc42ecb4e173f94b8a1739",
            "023b5d9fd72846af839cf2bcc5c9847d",
            "4edc65a77c5741728dcbb9c9589fb03a",
            "436d9940170d42fcb3ff16db58e1e9f4",
            "d6c23b5176ac41a48d3131eb5c536e08",
            "f048431f8081478094558c41b101ed7f",
            "487a811daf9544bea5886f00c784c5ad",
            "89e4753bd37c430f87394deb0942bcd5",
            "31052ab1ca834bda8b95b72ea6c17989",
            "5b58de45e885424fb3daa6bd6d697cef",
            "eea53d26cb534f93972921f3e2376591",
            "22dc30bcd04347198d9e4d977bd6cb88",
            "2df74b8b1be849de9421bc291db7ed6c",
            "1b1aece8cda44142910d80b28771469a",
            "a3f6032308a54b0584b6593d288a8b24",
            "5fd15a514e1144418ab6408e0fd9f7b1"
          ]
        },
        "outputId": "39ce3450-f2b9-426a-9a9d-bf92bd8b4036"
      },
      "source": [
        "d_test_tiny = Dataset('test', PROJECT_DIR)\n",
        "pred = Model.stacked_test(d_test_tiny, ['models/best6', 'models/best_resnet', 'models/best_densenet'])\n",
        "Metrics.print_all(d_test_tiny.labels, pred, 'test')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset test from npz.\n",
            "Done. Dataset test consists of 4500 images.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89ce09305dd41a18deb794ce9e7abbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model models/best6 evaluated\n",
            "Changing preprocessor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffa971f148bc42ecb4e173f94b8a1739",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model models/best_resnet evaluated\n",
            "Changing preprocessor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31052ab1ca834bda8b95b72ea6c17989",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model models/best_densenet evaluated\n",
            "metrics for test:\n",
            "['0 : 0', '0 : 0', '0 : 0', '0 : 0', '0 : 0']\n",
            "\t accuracy 0.9544:\n",
            "\t balanced accuracy 0.9544:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPvyj4gscU10"
      },
      "source": [
        "Отмонтировать Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfX35zNSvFWn"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMyDxCDCspcI"
      },
      "source": [
        "---\n",
        "# Дополнительные \"полезности\"\n",
        "\n",
        "Ниже приведены примеры использования различных функций и библиотек, которые могут быть полезны при выполнении данного практического задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvLwSttCs1rB"
      },
      "source": [
        "### Измерение времени работы кода\n",
        "\n",
        "Измерять время работы какой-либо функции можно легко и непринужденно при помощи функции timeit из соответствующего модуля:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnLVhwE9C9S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fa95fae8-7553-4c53-ffdb-eab00b19e1b8"
      },
      "source": [
        "'''import timeit\n",
        "\n",
        "def factorial(n):\n",
        "    res = 1\n",
        "    for i in range(1, n + 1):\n",
        "        res *= i\n",
        "    return res\n",
        "\n",
        "\n",
        "def f():\n",
        "    return factorial(n=1000)\n",
        "\n",
        "n_runs = 128\n",
        "print(f'Function f is caluclated {n_runs} times in {timeit.timeit(f, number=n_runs)}s.')'''"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import timeit\\n\\ndef factorial(n):\\n    res = 1\\n    for i in range(1, n + 1):\\n        res *= i\\n    return res\\n\\n\\ndef f():\\n    return factorial(n=1000)\\n\\nn_runs = 128\\nprint(f'Function f is caluclated {n_runs} times in {timeit.timeit(f, number=n_runs)}s.')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fibGVEdguOOi"
      },
      "source": [
        "### Scikit-learn\n",
        "\n",
        "Для использования \"классических\" алгоритмов машинного обучения рекомендуется использовать библиотеку scikit-learn (https://scikit-learn.org/stable/). Пример классификации изображений цифр из набора данных MNIST при помощи классификатора SVM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXHnBzEfunAO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "3aac7130-7c41-4243-fc35-737401741c0b"
      },
      "source": [
        "'''# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# The data that we are interested in is made of 8x8 images of digits, let's\n",
        "# have a look at the first 4 images, stored in the `images` attribute of the\n",
        "# dataset.  If we were working from image files, we could load them using\n",
        "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
        "# images, we know which digit they represent: it is given in the 'target' of\n",
        "# the dataset.\n",
        "_, axes = plt.subplots(2, 4)\n",
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Training: %i' % label)\n",
        "\n",
        "# To apply a classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Split data into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.5, shuffle=False)\n",
        "\n",
        "# We learn the digits on the first half of the digits\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = classifier.predict(X_test)\n",
        "\n",
        "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
        "for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Prediction: %i' % prediction)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Standard scientific Python imports\\nimport matplotlib.pyplot as plt\\n\\n# Import datasets, classifiers and performance metrics\\nfrom sklearn import datasets, svm, metrics\\nfrom sklearn.model_selection import train_test_split\\n\\n# The digits dataset\\ndigits = datasets.load_digits()\\n\\n# The data that we are interested in is made of 8x8 images of digits, let\\'s\\n# have a look at the first 4 images, stored in the `images` attribute of the\\n# dataset.  If we were working from image files, we could load them using\\n# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\\n# images, we know which digit they represent: it is given in the \\'target\\' of\\n# the dataset.\\n_, axes = plt.subplots(2, 4)\\nimages_and_labels = list(zip(digits.images, digits.target))\\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\\n    ax.set_axis_off()\\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\\'nearest\\')\\n    ax.set_title(\\'Training: %i\\' % label)\\n\\n# To apply a classifier on this data, we need to flatten the image, to\\n# turn the data in a (samples, feature) matrix:\\nn_samples = len(digits.images)\\ndata = digits.images.reshape((n_samples, -1))\\n\\n# Create a classifier: a support vector classifier\\nclassifier = svm.SVC(gamma=0.001)\\n\\n# Split data into train and test subsets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    data, digits.target, test_size=0.5, shuffle=False)\\n\\n# We learn the digits on the first half of the digits\\nclassifier.fit(X_train, y_train)\\n\\n# Now predict the value of the digit on the second half:\\npredicted = classifier.predict(X_test)\\n\\nimages_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\\nfor ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\\n    ax.set_axis_off()\\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\\'nearest\\')\\n    ax.set_title(\\'Prediction: %i\\' % prediction)\\n\\nprint(\"Classification report for classifier %s:\\n%s\\n\"\\n      % (classifier, metrics.classification_report(y_test, predicted)))\\ndisp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\\ndisp.figure_.suptitle(\"Confusion Matrix\")\\nprint(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\\n\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu3Dny5zxcVy"
      },
      "source": [
        "### Scikit-image\n",
        "\n",
        "Реализовывать различные операции для работы с изображениями можно как самостоятельно, работая с массивами numpy, так и используя специализированные библиотеки, например, scikit-image (https://scikit-image.org/). Ниже приведен пример использования Canny edge detector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TZvy_d7xc0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c1f175fd-8add-428e-b119-2c8aaebf9969"
      },
      "source": [
        "'''import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage import feature\n",
        "\n",
        "\n",
        "# Generate noisy image of a square\n",
        "im = np.zeros((128, 128))\n",
        "im[32:-32, 32:-32] = 1\n",
        "\n",
        "im = ndi.rotate(im, 15, mode='constant')\n",
        "im = ndi.gaussian_filter(im, 4)\n",
        "im += 0.2 * np.random.random(im.shape)\n",
        "\n",
        "# Compute the Canny filter for two values of sigma\n",
        "edges1 = feature.canny(im)\n",
        "edges2 = feature.canny(im, sigma=3)\n",
        "\n",
        "# display results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n",
        "                                    sharex=True, sharey=True)\n",
        "\n",
        "ax1.imshow(im, cmap=plt.cm.gray)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('noisy image', fontsize=20)\n",
        "\n",
        "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
        "ax2.axis('off')\n",
        "ax2.set_title(r'Canny filter, $\\sigma=1$', fontsize=20)\n",
        "\n",
        "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
        "ax3.axis('off')\n",
        "ax3.set_title(r'Canny filter, $\\sigma=3$', fontsize=20)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy import ndimage as ndi\\n\\nfrom skimage import feature\\n\\n\\n# Generate noisy image of a square\\nim = np.zeros((128, 128))\\nim[32:-32, 32:-32] = 1\\n\\nim = ndi.rotate(im, 15, mode='constant')\\nim = ndi.gaussian_filter(im, 4)\\nim += 0.2 * np.random.random(im.shape)\\n\\n# Compute the Canny filter for two values of sigma\\nedges1 = feature.canny(im)\\nedges2 = feature.canny(im, sigma=3)\\n\\n# display results\\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\\n                                    sharex=True, sharey=True)\\n\\nax1.imshow(im, cmap=plt.cm.gray)\\nax1.axis('off')\\nax1.set_title('noisy image', fontsize=20)\\n\\nax2.imshow(edges1, cmap=plt.cm.gray)\\nax2.axis('off')\\nax2.set_title(r'Canny filter, $\\\\sigma=1$', fontsize=20)\\n\\nax3.imshow(edges2, cmap=plt.cm.gray)\\nax3.axis('off')\\nax3.set_title(r'Canny filter, $\\\\sigma=3$', fontsize=20)\\n\\nfig.tight_layout()\\n\\nplt.show()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiEWhGUQRGoH"
      },
      "source": [
        "### Tensorflow 2\n",
        "\n",
        "Для создания и обучения нейросетевых моделей можно использовать фреймворк глубокого обучения Tensorflow 2. Ниже приведен пример простейшей нейроной сети, использующейся для классификации изображений из набора данных MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwLG7A1ReNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "11751b88-c82d-406f-f937-1917eb7d0c87"
      },
      "source": [
        "'''# Install TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"# Install TensorFlow\\n\\nimport tensorflow as tf\\n\\nmnist = tf.keras.datasets.mnist\\n\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n\\nmodel = tf.keras.models.Sequential([\\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\\n  tf.keras.layers.Dense(128, activation='relu'),\\n  tf.keras.layers.Dropout(0.2),\\n  tf.keras.layers.Dense(10, activation='softmax')\\n])\\n\\nmodel.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',\\n              metrics=['accuracy'])\\n\\nmodel.fit(x_train, y_train, epochs=5)\\n\\nmodel.evaluate(x_test,  y_test, verbose=2)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvktmLwRu8g"
      },
      "source": [
        "<font color=\"red\">\n",
        "Для эффективной работы с моделями глубокого обучения убедитесь в том, что в текущей среде Google Colab используется аппаратный ускоритель GPU или TPU. Для смены среды выберите \"среда выполнения\" -> \"сменить среду выполнения\".\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJVNOOU9Sjyf"
      },
      "source": [
        "Большое количество туториалов и примеров с кодом на Tensorflow 2 можно найти на официальном сайте https://www.tensorflow.org/tutorials?hl=ru. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPs3pYpS0U1"
      },
      "source": [
        "Также, Вам может понадобиться написать собственный генератор данных для Tensorflow 2. Скорее всего он будет достаточно простым, и его легко можно будет реализовать, используя официальную документацию TensorFlow 2. Но, на всякий случай (если не удлось сразу разобраться или хочется вникнуть в тему более глубоко), можете посмотреть следующий отличный туториал: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwI-T0IXyN84"
      },
      "source": [
        "### Numba\n",
        "\n",
        "В некоторых ситуациях, при ручных реализациях графовых алгоритмов, выполнение многократных вложенных циклов for в python можно существенно ускорить, используя JIT-компилятор Numba (https://numba.pydata.org/).\n",
        "Примеры использования Numba в Google Colab можно найти тут:\n",
        "1. https://colab.research.google.com/github/cbernet/maldives/blob/master/numba/numba_cuda.ipynb\n",
        "2. https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/COMPASS_gpu_intro.ipynb \n",
        "\n",
        "> Пожалуйста, если Вы решили использовать Numba для решения этого практического задания, еще раз подумайте, нужно ли это Вам, и есть ли возможность реализовать требуемую функциональность иным способом. Используйте Numba только при реальной необходимости.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxAJ00A76LcF"
      },
      "source": [
        "### Работа с zip архивами в Google Drive\n",
        "\n",
        "Запаковка и распаковка zip архивов может пригодиться при сохранении и загрузки Вашей модели. Ниже приведен фрагмент кода, иллюстрирующий помещение нескольких файлов в zip архив с последующим чтением файлов из него. Все действия с директориями, файлами и архивами должны осущетвляться с примонтированным Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJiKndOpPu_e"
      },
      "source": [
        "Создадим 2 изображения, поместим их в директорию tmp внутри PROJECT_DIR, запакуем директорию tmp в архив tmp.zip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRwgPtv-6nMP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "04229656-9a30-4885-9c89-317ac921558a"
      },
      "source": [
        "'''arr1 = np.random.rand(100, 100, 3) * 255\n",
        "arr2 = np.random.rand(100, 100, 3) * 255\n",
        "\n",
        "img1 = Image.fromarray(arr1.astype('uint8'))\n",
        "img2 = Image.fromarray(arr2.astype('uint8'))\n",
        "\n",
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "\n",
        "if not (Path(p) / 'tmp').exists():\n",
        "    (Path(p) / 'tmp').mkdir()\n",
        "\n",
        "img1.save(str(Path(p) / 'tmp' / 'img1.png'))\n",
        "img2.save(str(Path(p) / 'tmp' / 'img2.png'))\n",
        "\n",
        "%cd $p\n",
        "!zip -r \"tmp.zip\" \"tmp\"'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'arr1 = np.random.rand(100, 100, 3) * 255\\narr2 = np.random.rand(100, 100, 3) * 255\\n\\nimg1 = Image.fromarray(arr1.astype(\\'uint8\\'))\\nimg2 = Image.fromarray(arr2.astype(\\'uint8\\'))\\n\\np = \"/content/drive/MyDrive/\" + PROJECT_DIR\\n\\nif not (Path(p) / \\'tmp\\').exists():\\n    (Path(p) / \\'tmp\\').mkdir()\\n\\nimg1.save(str(Path(p) / \\'tmp\\' / \\'img1.png\\'))\\nimg2.save(str(Path(p) / \\'tmp\\' / \\'img2.png\\'))\\n\\n%cd $p\\n!zip -r \"tmp.zip\" \"tmp\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MykrBSWNQQlq"
      },
      "source": [
        "Распакуем архив tmp.zip в директорию tmp2 в PROJECT_DIR. Теперь внутри директории tmp2 содержится директория tmp, внутри которой находятся 2 изображения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwSWrYIWMAus",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bcb665c1-2531-4b10-b8d4-06cee712787d"
      },
      "source": [
        "'''p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "%cd $p\n",
        "!unzip -uq \"tmp.zip\" -d \"tmp2\"'''"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'p = \"/content/drive/MyDrive/\" + PROJECT_DIR\\n%cd $p\\n!unzip -uq \"tmp.zip\" -d \"tmp2\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}